{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoLc-F4Az7lI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.datasets import mnist \n",
    "from keras.layers import Dense, Input, concatenate,subtract, Lambda, Dropout\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFKvbJStrztH"
   },
   "outputs": [],
   "source": [
    "class Utils(object):\n",
    "    @classmethod\n",
    "    def create_pairs(cls, classes, count):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "\n",
    "        inx = np.random.randint(low=0, high=len(classes), size=(count, 2))\n",
    "        df = pd.DataFrame(data=inx, columns=[\"i1\", \"i2\"])\n",
    "        df[\"c1\"] = df[\"i1\"].map(lambda x:classes[x])\n",
    "        df[\"c2\"] = df[\"i2\"].map(lambda x:classes[x])\n",
    "        df[\"pos\"] = df[\"c1\"] == df[\"c2\"]\n",
    "        return df.drop_duplicates()\n",
    "\n",
    "    @classmethod\n",
    "    def image_to_patches(cls, path, shape, patches):\n",
    "        from sklearn.feature_extraction import image\n",
    "        from skimage.io import imread\n",
    "        img = imread(path)\n",
    "        return image.extract_patches_2d(img, shape, patches)\n",
    "\n",
    "    @classmethod\n",
    "    def select_random_class_indecies(cls, wanted_classes, classes_indecies, count=1, replace=False):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def get_other_classes_random(cls, classes_list, unique_classes):\n",
    "        import random\n",
    "\n",
    "        unique = set(unique_classes)\n",
    "        return [random.choice(tuple(unique - set([c]))) for c in classes_list]\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def create_siamese_pairs_1(cls, original_class_list, pos_count, neg_count,\n",
    "                               drop_dups=True, shuffle=True):\n",
    "        import numpy as np\n",
    "\n",
    "        if not isinstance(original_class_list, np.ndarray):\n",
    "            original_class_list = np.array(original_class_list)\n",
    "\n",
    "        left = np.random.choice(original_class_list, pos_count+neg_count)\n",
    "\n",
    "        #unique_classes = np.unique(original_class_list)\n",
    "        pos_classes = list(left[:pos_count])\n",
    "        neg_classes = cls.get_other_classes_random(left[pos_count:], original_class_list)\n",
    "        right = pos_classes + neg_classes\n",
    "\n",
    "        left = cls.sample_indecies_for_classes(original_class_list, left)\n",
    "        right = cls.sample_indecies_for_classes(original_class_list, right)\n",
    "\n",
    "        tags = [1] * pos_count + [0] * neg_count\n",
    "        data = np.array([left, right, tags]).transpose()\n",
    "\n",
    "        if drop_dups:\n",
    "            data = np.unique(data, axis=0)\n",
    "\n",
    "        if shuffle:\n",
    "            i = np.arange(len(data))\n",
    "            np.random.shuffle(i)\n",
    "            data = data[i]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def sample_indecies_for_classes(cls, original_classes_list, classes_to_sample):\n",
    "        import numpy as np\n",
    "        import random\n",
    "\n",
    "        unique_classes = np.unique(original_classes_list)\n",
    "\n",
    "        if not isinstance(original_classes_list, np.ndarray):\n",
    "            original_classes_list = np.array(original_classes_list)\n",
    "\n",
    "        c2i = {c: np.where(original_classes_list == c)[0].astype(int).tolist()\n",
    "               for c in unique_classes}\n",
    "\n",
    "        arr = np.zeros(shape=len(classes_to_sample))\n",
    "        for i, c in enumerate(classes_to_sample):\n",
    "            arr[i] = random.choice(c2i[c])\n",
    "\n",
    "        return arr.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzlMAgMS3AGf"
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EGIUDhz3Ac2"
   },
   "outputs": [],
   "source": [
    "train_x = (train_x / 255.0).reshape(-1, 28*28) \n",
    "test_x = (test_x / 255.0).reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "kCjUoSVE3AxE",
    "outputId": "16a89fda-d3a5-4037-bc2c-b3c1f0cd5dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shai/anaconda3/envs/siamese/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/shai/anaconda3/envs/siamese/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "inp1 = Input(shape=(28*28,))\n",
    "inp2 = Input(shape=(28*28,))\n",
    "\n",
    "l1 = Dense(100, activation=\"relu\")\n",
    "a1 = l1(inp1)\n",
    "a2 = l1(inp2)\n",
    "\n",
    "l2 = Dense(50, activation=\"relu\")\n",
    "b1 = l2(a1)\n",
    "b2 = l2(a2)\n",
    "\n",
    "output = Lambda(lambda inputs: np.absolute(inputs[0]-inputs[1]), output_shape=(50,))([b1, b2])\n",
    "output = Dropout(0.3)(output)\n",
    "\n",
    "output1 = Dense(1)(output)\n",
    "\n",
    "model = Model([inp1, inp2], [output1])\n",
    "model.compile(loss=binary_crossentropy, optimizer=SGD(lr = 0.0001)) \n",
    "\n",
    "#this model is not learning, so don't need to compile it.\n",
    "encoder = Model([inp1, inp2], [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjHLP35ssJnQ"
   },
   "outputs": [],
   "source": [
    "uc = np.unique(train_y)\n",
    "data = Utils.create_siamese_pairs_1(train_y, 300000, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "9b4NCiK8-Fsz",
    "outputId": "57e58bd3-892e-491c-e1ef-c959d85fd53f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shai/anaconda3/envs/siamese/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 485894 samples, validate on 53989 samples\n",
      "Epoch 1/5\n",
      "485894/485894 [==============================] - 66s 137us/step - loss: 0.7823 - val_loss: 0.6703\n",
      "Epoch 2/5\n",
      "485894/485894 [==============================] - 65s 134us/step - loss: 0.6507 - val_loss: 0.5926\n",
      "Epoch 3/5\n",
      "485894/485894 [==============================] - 65s 135us/step - loss: 0.5963 - val_loss: 0.5381\n",
      "Epoch 4/5\n",
      "485894/485894 [==============================] - 65s 134us/step - loss: 0.5616 - val_loss: 0.5023\n",
      "Epoch 5/5\n",
      "485894/485894 [==============================] - 65s 135us/step - loss: 0.5452 - val_loss: 0.5022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ead2cc0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = int(len(data)*0.1)\n",
    "ind = np.arange(len(data))\n",
    "np.random.shuffle(ind)\n",
    "data, test = data[ind[:-test_size]], data[ind[-test_size:]]\n",
    "model.fit([train_x[data[:,0]], train_x[data[:,1]]], data[:,2], epochs=5, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "2ZUENQDU7Lx4",
    "outputId": "5228e9b8-c3ee-4bb8-bfa2-c2739d38ee34"
   },
   "outputs": [],
   "source": [
    "#creating the training set for the classifiers\n",
    "train_x_siamese = encoder.predict([train_x[data[:,0]], train_x[data[:,1]]])\n",
    "train_x_euc = np.absolute(train_x[data[:,0]] - train_x[data[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the test set for the classifiers\n",
    "test_x = [train_x[test[:,0]], train_x[test[:,1]]]\n",
    "test_y = test[:,2]\n",
    "test_x_siamese = encoder.predict([test_x[0], test_x[1]])\n",
    "test_x_euc = np.absolute(test_x[0] - test_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the classifiers, generally we can use SVM, as it should be stronger, \n",
    "#but its so painfully slow on large datasets with a lot of dimensions\n",
    "clf1 = linear_model.SGDClassifier()\n",
    "clf2 = linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(train_x_siamese, data[:,2])\n",
    "clf2.fit(train_x_euc, data[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = clf1.predict(test_x_siamese)\n",
    "t2 = clf2.predict(test_x_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015203547494415 0.7409395525622645\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_y, t1), accuracy_score(test_y, t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we can see that the siamese network gives us better accuracy, with a faster supervised learning task, this means that the spatial representation is better then the original one in terms of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "article 2",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
